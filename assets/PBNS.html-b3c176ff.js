const e=JSON.parse(`{"key":"v-101b27aa","path":"/posts/paper/PBNS.html","title":"PBNS-论文笔记","lang":"zh-CN","frontmatter":{"date":"2024-05-20T00:00:00.000Z","category":"论文","tag":["Paper","Physical Simulation","PBNS"],"title":"PBNS-论文笔记","order":13,"description":"PBNS: Physically Based Neural Simulator for Unsupervised Garment Pose Space Deformation 项目地址 TOG 2021 Abstract 我们提出了一种通过深度学习自动获取服装 pose 空间变形 (Pose Space Deformation, PSD) 的方法。经典方法依赖基于物理的模拟 (Physically Based Simulations, PBS) 来制作服装动画。这是一种通用的解决方案，只要对空间和时间进行足够精细的离散化，就能获得高度逼真的效果。然而，它们的计算成本很高，而且任何场景的修改都需要重新模拟。使用 PSD 的线性混合蒙皮 (LBS) 为 PBS 提供了一个轻量级的替代方案，不过它需要大量数据来学习适当的 PSD。我们建议使用深度学习，并将其表述为隐式 PBS，以无监督的方式学习受限场景中的真实布料 pose 空间变形：穿衣人体。此外，我们还展示了在与几个序列的 PBS 相当的时间内训练这些模型的可能性。据我们所知，我们是第一个提出布料神经模拟器的人。虽然该领域基于深度的方法正成为一种趋势，但这些模型对数据的需求量很大。此外，作者通常会提出复杂的公式，以便更好地从 PBS 数据中学习褶皱。监督学习会导致物理上不一致的预测，需要使用碰撞解法。同时，对 PBS 数据的依赖限制了这些解决方案的可扩展性，而它们的表述方式又阻碍了其适用性和兼容性。通过提出一种无监督方法来学习 LBS 模型的 PSD，我们克服了这两个缺点。研究结果表明，在动画中保持了服装一致性以及与姿势相关的服装褶皱。我们的解决方案非常高效，可以处理多层布料，允许在无监督的情况下调整服装尺寸，并可轻松应用于任何自定义 3D 数字人。","head":[["meta",{"property":"og:url","content":"https://rocyan.top/posts/paper/PBNS.html"}],["meta",{"property":"og:site_name","content":"Roc Yan's Blog"}],["meta",{"property":"og:title","content":"PBNS-论文笔记"}],["meta",{"property":"og:description","content":"PBNS: Physically Based Neural Simulator for Unsupervised Garment Pose Space Deformation 项目地址 TOG 2021 Abstract 我们提出了一种通过深度学习自动获取服装 pose 空间变形 (Pose Space Deformation, PSD) 的方法。经典方法依赖基于物理的模拟 (Physically Based Simulations, PBS) 来制作服装动画。这是一种通用的解决方案，只要对空间和时间进行足够精细的离散化，就能获得高度逼真的效果。然而，它们的计算成本很高，而且任何场景的修改都需要重新模拟。使用 PSD 的线性混合蒙皮 (LBS) 为 PBS 提供了一个轻量级的替代方案，不过它需要大量数据来学习适当的 PSD。我们建议使用深度学习，并将其表述为隐式 PBS，以无监督的方式学习受限场景中的真实布料 pose 空间变形：穿衣人体。此外，我们还展示了在与几个序列的 PBS 相当的时间内训练这些模型的可能性。据我们所知，我们是第一个提出布料神经模拟器的人。虽然该领域基于深度的方法正成为一种趋势，但这些模型对数据的需求量很大。此外，作者通常会提出复杂的公式，以便更好地从 PBS 数据中学习褶皱。监督学习会导致物理上不一致的预测，需要使用碰撞解法。同时，对 PBS 数据的依赖限制了这些解决方案的可扩展性，而它们的表述方式又阻碍了其适用性和兼容性。通过提出一种无监督方法来学习 LBS 模型的 PSD，我们克服了这两个缺点。研究结果表明，在动画中保持了服装一致性以及与姿势相关的服装褶皱。我们的解决方案非常高效，可以处理多层布料，允许在无监督的情况下调整服装尺寸，并可轻松应用于任何自定义 3D 数字人。"}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2024-05-20T03:08:46.000Z"}],["meta",{"property":"article:author","content":"Roc Yan"}],["meta",{"property":"article:tag","content":"Paper"}],["meta",{"property":"article:tag","content":"Physical Simulation"}],["meta",{"property":"article:tag","content":"PBNS"}],["meta",{"property":"article:published_time","content":"2024-05-20T00:00:00.000Z"}],["meta",{"property":"article:modified_time","content":"2024-05-20T03:08:46.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"PBNS-论文笔记\\",\\"image\\":[\\"\\"],\\"datePublished\\":\\"2024-05-20T00:00:00.000Z\\",\\"dateModified\\":\\"2024-05-20T03:08:46.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"Roc Yan\\",\\"url\\":\\"https://rocyan.top\\",\\"email\\":\\"qpyan23@m.fudan.edu.cn\\"}]}"]]},"headers":[{"level":2,"title":"PBNS: Physically Based Neural Simulator for Unsupervised Garment Pose Space Deformation","slug":"pbns-physically-based-neural-simulator-for-unsupervised-garment-pose-space-deformation","link":"#pbns-physically-based-neural-simulator-for-unsupervised-garment-pose-space-deformation","children":[]},{"level":2,"title":"Abstract","slug":"abstract","link":"#abstract","children":[]},{"level":2,"title":"Introduction","slug":"introduction","link":"#introduction","children":[]},{"level":2,"title":"Neural Cloth Simulation","slug":"neural-cloth-simulation","link":"#neural-cloth-simulation","children":[]}],"git":{"createdTime":1716174479000,"updatedTime":1716174526000,"contributors":[{"name":"Yan","email":"rocyan98@gmail.com","commits":2}]},"readingTime":{"minutes":3.56,"words":1067},"filePathRelative":"posts/paper/PBNS.md","localizedDate":"2024年5月20日","excerpt":"<h2> PBNS: Physically Based Neural Simulator for Unsupervised Garment Pose Space Deformation</h2>\\n<p><a href=\\"https://hbertiche.github.io/PBNS\\" target=\\"_blank\\" rel=\\"noopener noreferrer\\">项目地址</a></p>\\n<p>TOG 2021</p>\\n<h2> Abstract</h2>\\n<p>我们提出了一种通过深度学习自动获取服装 <strong>pose 空间变形 (Pose Space Deformation, PSD)</strong> 的方法。经典方法依赖基于<strong>物理的模拟 (Physically Based Simulations, PBS)</strong> 来制作服装动画。这是一种通用的解决方案，只要对空间和时间进行足够精细的离散化，就能获得高度逼真的效果。然而，它们的计算成本很高，而且任何场景的修改都需要重新模拟。使用 PSD 的<strong>线性混合蒙皮 (LBS)</strong> 为 PBS 提供了一个轻量级的替代方案，不过它需要大量数据来学习适当的 PSD。我们建议使用深度学习，并将其表述为隐式 PBS，以无监督的方式学习受限场景中的真实布料 pose 空间变形：穿衣人体。此外，我们还展示了在与几个序列的 PBS 相当的时间内训练这些模型的可能性。据我们所知，我们是第一个提出布料神经模拟器的人。虽然该领域基于深度的方法正成为一种趋势，但这些模型对数据的需求量很大。此外，作者通常会提出复杂的公式，以便更好地从 PBS 数据中学习褶皱。监督学习会导致物理上不一致的预测，需要使用碰撞解法。同时，对 PBS 数据的依赖限制了这些解决方案的可扩展性，而它们的表述方式又阻碍了其适用性和兼容性。通过提出一种无监督方法来学习 LBS 模型的 PSD，我们克服了这两个缺点。研究结果表明，在动画中保持了服装一致性以及与姿势相关的服装褶皱。我们的解决方案非常高效，可以处理多层布料，允许在无监督的情况下调整服装尺寸，并可轻松应用于任何自定义 3D 数字人。</p>","autoDesc":true}`);export{e as data};
