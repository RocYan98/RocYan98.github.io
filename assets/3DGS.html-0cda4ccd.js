const e=JSON.parse(`{"key":"v-bc5d60f8","path":"/posts/paper/3DGS.html","title":"3DGS-论文笔记","lang":"zh-CN","frontmatter":{"date":"2024-03-15T00:00:00.000Z","category":"论文","tag":["Paper","3DGS","3D Reconstruction"],"title":"3DGS-论文笔记","order":7,"description":"3D Gaussian Splatting for Real-Time Radiance Field Rendering 项目地址 SIGGRAPH 2023 Abstract 辐射场方法最近彻底改变了用多张照片或视频拍摄的场景的新视角合成。然而，要实现高视觉质量，仍然需要神经网络，而神经网络的训练和渲染成本很高，同时，最近的快速方法不可避免地要以速度换质量。对于无边界的完整场景 (而不是孤立的物体) 和 1080p 分辨率渲染，目前的方法都无法实现实时显示率。我们引入了三个关键要素，使我们能够在保持有竞争力的训练时间的同时实现最先进的视觉质量，更重要的是，我们能够在 1080p 分辨率下实现高质量的实时 (≥ 30 fps) 新视图合成。首先，从摄像机标定过程中产生的稀疏点云开始，我们用三维高斯表示场景，这种三维高斯保留了用于场景优化的连续体积辐射场的理想特性，同时避免了在空白空间进行不必要的计算；其次，我们对三维高斯进行交错优化/密度控制，特别是优化各向异性协方差，以实现场景的精确表示；第三，我们开发了一种快速的可见性感知的渲染算法，该算法支持各向异性拼接，既能加快训练速度，又能实现实时渲染。我们在几个已建立的数据集上展示了最先进的视觉质量和实时渲染。","head":[["meta",{"property":"og:url","content":"https://rocyan.top/posts/paper/3DGS.html"}],["meta",{"property":"og:site_name","content":"Roc Yan's Blog"}],["meta",{"property":"og:title","content":"3DGS-论文笔记"}],["meta",{"property":"og:description","content":"3D Gaussian Splatting for Real-Time Radiance Field Rendering 项目地址 SIGGRAPH 2023 Abstract 辐射场方法最近彻底改变了用多张照片或视频拍摄的场景的新视角合成。然而，要实现高视觉质量，仍然需要神经网络，而神经网络的训练和渲染成本很高，同时，最近的快速方法不可避免地要以速度换质量。对于无边界的完整场景 (而不是孤立的物体) 和 1080p 分辨率渲染，目前的方法都无法实现实时显示率。我们引入了三个关键要素，使我们能够在保持有竞争力的训练时间的同时实现最先进的视觉质量，更重要的是，我们能够在 1080p 分辨率下实现高质量的实时 (≥ 30 fps) 新视图合成。首先，从摄像机标定过程中产生的稀疏点云开始，我们用三维高斯表示场景，这种三维高斯保留了用于场景优化的连续体积辐射场的理想特性，同时避免了在空白空间进行不必要的计算；其次，我们对三维高斯进行交错优化/密度控制，特别是优化各向异性协方差，以实现场景的精确表示；第三，我们开发了一种快速的可见性感知的渲染算法，该算法支持各向异性拼接，既能加快训练速度，又能实现实时渲染。我们在几个已建立的数据集上展示了最先进的视觉质量和实时渲染。"}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2024-05-07T03:42:30.000Z"}],["meta",{"property":"article:author","content":"Roc Yan"}],["meta",{"property":"article:tag","content":"Paper"}],["meta",{"property":"article:tag","content":"3DGS"}],["meta",{"property":"article:tag","content":"3D Reconstruction"}],["meta",{"property":"article:published_time","content":"2024-03-15T00:00:00.000Z"}],["meta",{"property":"article:modified_time","content":"2024-05-07T03:42:30.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"3DGS-论文笔记\\",\\"image\\":[\\"\\"],\\"datePublished\\":\\"2024-03-15T00:00:00.000Z\\",\\"dateModified\\":\\"2024-05-07T03:42:30.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"Roc Yan\\",\\"url\\":\\"https://rocyan.top\\",\\"email\\":\\"qpyan23@m.fudan.edu.cn\\"}]}"]]},"headers":[{"level":2,"title":"3D Gaussian Splatting for Real-Time Radiance Field Rendering","slug":"_3d-gaussian-splatting-for-real-time-radiance-field-rendering","link":"#_3d-gaussian-splatting-for-real-time-radiance-field-rendering","children":[]},{"level":2,"title":"Abstract","slug":"abstract","link":"#abstract","children":[]},{"level":2,"title":"Introduction","slug":"introduction","link":"#introduction","children":[]},{"level":2,"title":"可微 3DGS (Differentiable 3D Gaussian Splatting)","slug":"可微-3dgs-differentiable-3d-gaussian-splatting","link":"#可微-3dgs-differentiable-3d-gaussian-splatting","children":[]},{"level":2,"title":"3DGS 自适应密度控制 (Optimization With Adaptive Density Control Of 3D Gaussian)","slug":"_3dgs-自适应密度控制-optimization-with-adaptive-density-control-of-3d-gaussian","link":"#_3dgs-自适应密度控制-optimization-with-adaptive-density-control-of-3d-gaussian","children":[{"level":3,"title":"优化 (Optimization)","slug":"优化-optimization","link":"#优化-optimization","children":[]},{"level":3,"title":"高斯自适应控制 (Adaptive Control of Gaussians)","slug":"高斯自适应控制-adaptive-control-of-gaussians","link":"#高斯自适应控制-adaptive-control-of-gaussians","children":[]}]},{"level":2,"title":"快速可微光栅化","slug":"快速可微光栅化","link":"#快速可微光栅化","children":[]},{"level":2,"title":"Reference","slug":"reference","link":"#reference","children":[]}],"git":{"createdTime":1710899618000,"updatedTime":1715053350000,"contributors":[{"name":"Yan","email":"rocyan98@gmail.com","commits":6}]},"readingTime":{"minutes":4.59,"words":1377},"filePathRelative":"posts/paper/3DGS.md","localizedDate":"2024年3月15日","excerpt":"<h2> 3D Gaussian Splatting for Real-Time Radiance Field Rendering</h2>\\n<p><a href=\\"https://repo-sam.inria.fr/fungraph/3d-gaussian-splatting/\\" target=\\"_blank\\" rel=\\"noopener noreferrer\\">项目地址</a></p>\\n<p>SIGGRAPH 2023</p>\\n<h2> Abstract</h2>\\n<p>辐射场方法最近彻底改变了用多张照片或视频拍摄的场景的新视角合成。然而，要实现高视觉质量，仍然需要神经网络，而神经网络的训练和渲染成本很高，同时，最近的快速方法不可避免地要以速度换质量。对于无边界的完整场景 (而不是孤立的物体) 和 1080p 分辨率渲染，目前的方法都无法实现实时显示率。我们引入了三个关键要素，使我们能够在保持有竞争力的训练时间的同时实现最先进的视觉质量，更重要的是，我们能够在 1080p 分辨率下实现高质量的实时 (≥ 30 fps) 新视图合成。首先，从摄像机标定过程中产生的稀疏点云开始，我们用三维高斯表示场景，这种三维高斯保留了用于场景优化的连续体积辐射场的理想特性，同时避免了在空白空间进行不必要的计算；其次，我们对三维高斯进行交错优化/密度控制，特别是优化各向异性协方差，以实现场景的精确表示；第三，我们开发了一种快速的可见性感知的渲染算法，该算法支持各向异性拼接，既能加快训练速度，又能实现实时渲染。我们在几个已建立的数据集上展示了最先进的视觉质量和实时渲染。</p>","autoDesc":true}`);export{e as data};
