const t=JSON.parse(`{"key":"v-4218968d","path":"/posts/paper/FITE.html","title":"FITE-论文笔记","lang":"zh-CN","frontmatter":{"date":"2024-04-25T00:00:00.000Z","category":"论文","tag":["Paper","Avatar","FITE","SDF"],"title":"FITE-论文笔记","order":11,"description":"Learning Implicit Templates for Point-Based Clothed Human Modeling 项目地址 ECCV 2022 Abstract 我们提出的 FITE (First-Implicit-Then-Explicit) 是一个先隐后显的框架，用于为穿着服装的数字人建模。我们的框架首先学习表示粗略服装拓扑结构的隐式表面模板，然后利用模板指导点集的生成，进一步捕捉与姿势相关的服装变形（如褶皱）。我们的管道结合了隐式和显式表示法的优点，即能够处理不同的拓扑结构，并能有效捕捉精细细节。我们还提出了扩散蒙皮技术，以方便模板训练，尤其是宽松服装的模板训练，以及通过基于投影的 pose 编码从 mesh 模板中提取 pose 信息，而无需预定义的 UV 贴图或连通性。","head":[["meta",{"property":"og:url","content":"https://rocyan.top/posts/paper/FITE.html"}],["meta",{"property":"og:site_name","content":"Roc Yan's Blog"}],["meta",{"property":"og:title","content":"FITE-论文笔记"}],["meta",{"property":"og:description","content":"Learning Implicit Templates for Point-Based Clothed Human Modeling 项目地址 ECCV 2022 Abstract 我们提出的 FITE (First-Implicit-Then-Explicit) 是一个先隐后显的框架，用于为穿着服装的数字人建模。我们的框架首先学习表示粗略服装拓扑结构的隐式表面模板，然后利用模板指导点集的生成，进一步捕捉与姿势相关的服装变形（如褶皱）。我们的管道结合了隐式和显式表示法的优点，即能够处理不同的拓扑结构，并能有效捕捉精细细节。我们还提出了扩散蒙皮技术，以方便模板训练，尤其是宽松服装的模板训练，以及通过基于投影的 pose 编码从 mesh 模板中提取 pose 信息，而无需预定义的 UV 贴图或连通性。"}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2024-04-25T03:04:01.000Z"}],["meta",{"property":"article:author","content":"Roc Yan"}],["meta",{"property":"article:tag","content":"Paper"}],["meta",{"property":"article:tag","content":"Avatar"}],["meta",{"property":"article:tag","content":"FITE"}],["meta",{"property":"article:tag","content":"SDF"}],["meta",{"property":"article:published_time","content":"2024-04-25T00:00:00.000Z"}],["meta",{"property":"article:modified_time","content":"2024-04-25T03:04:01.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"FITE-论文笔记\\",\\"image\\":[\\"\\"],\\"datePublished\\":\\"2024-04-25T00:00:00.000Z\\",\\"dateModified\\":\\"2024-04-25T03:04:01.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"Roc Yan\\",\\"url\\":\\"https://rocyan.top\\",\\"email\\":\\"qpyan23@m.fudan.edu.cn\\"}]}"]]},"headers":[{"level":2,"title":"Learning Implicit Templates for Point-Based Clothed Human Modeling","slug":"learning-implicit-templates-for-point-based-clothed-human-modeling","link":"#learning-implicit-templates-for-point-based-clothed-human-modeling","children":[]},{"level":2,"title":"Abstract","slug":"abstract","link":"#abstract","children":[]},{"level":2,"title":"Introduction","slug":"introduction","link":"#introduction","children":[]}],"git":{"createdTime":1714012605000,"updatedTime":1714014241000,"contributors":[{"name":"rocyan","email":"rocyan98@gmail.com","commits":6},{"name":"Yan","email":"rocyan98@gmail.com","commits":2}]},"readingTime":{"minutes":0.79,"words":237},"filePathRelative":"posts/paper/FITE.md","localizedDate":"2024年4月25日","excerpt":"<h2> Learning Implicit Templates for Point-Based Clothed Human Modeling</h2>\\n<p><a href=\\"https://jsnln.github.io/fite/index.html\\" target=\\"_blank\\" rel=\\"noopener noreferrer\\">项目地址</a></p>\\n<p>ECCV 2022</p>\\n<h2> Abstract</h2>\\n<p>我们提出的 FITE (First-Implicit-Then-Explicit) 是一个先隐后显的框架，用于为穿着服装的数字人建模。我们的框架首先学习表示粗略服装拓扑结构的隐式表面模板，然后利用模板指导点集的生成，进一步捕捉与姿势相关的服装变形（如褶皱）。我们的管道结合了隐式和显式表示法的优点，即能够处理不同的拓扑结构，并能有效捕捉精细细节。我们还提出了扩散蒙皮技术，以方便模板训练，尤其是宽松服装的模板训练，以及通过基于投影的 pose 编码从 mesh 模板中提取 pose 信息，而无需预定义的 UV 贴图或连通性。</p>","autoDesc":true}`);export{t as data};
