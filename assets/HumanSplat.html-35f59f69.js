import{_ as n,r,o as i,c as s,b as a,e,d as o,f as l}from"./app-3cfa580b.js";const c={},h=a("h2",{id:"humansplat-generalizable-single-image-human-gaussian-splatting-with-structure-priors",tabindex:"-1"},[a("a",{class:"header-anchor",href:"#humansplat-generalizable-single-image-human-gaussian-splatting-with-structure-priors","aria-hidden":"true"},"#"),e(" HumanSplat: Generalizable Single-Image Human Gaussian Splatting with Structure Priors")],-1),u={href:"https://humansplat.github.io",target:"_blank",rel:"noopener noreferrer"},d=l('<p>NeurlPS 2024</p><figure><img src="https://rocyan.oss-cn-hangzhou.aliyuncs.com/blog/202410251455125.png" alt="Fig. 1: Overview" tabindex="0" loading="lazy"><figcaption>Fig. 1: Overview</figcaption></figure><h2 id="abstract" tabindex="-1"><a class="header-anchor" href="#abstract" aria-hidden="true">#</a> Abstract</h2><p>尽管高保真人体重建技术取得了最新进展，但通常需要大量的输入图像或优化时间，这极大地阻碍了它们在更广泛的场景中的应用。为了解决这些问题，我们提出了 HumanSplat，它以生成的方式从单个输入图像预测任何人的 3DGS 属性。具体来说，HumanSplat 包括一个 2D 多视角扩散模型和一个具有人体结构先验的潜在重建 Transformer，能够巧妙地将几何先验和语义特征整合在统一框架中。此外，我们设计了一个分层损失，结合了人体语义信息，以实现高保真的纹理建模，并更好地约束估计的多视角。标准 benchmarks 和真实场景图像上的综合实验表明，HumanSplat 在实现逼真的新视角合成方面超越了现有的 SOTA。</p><h2 id="introduction" tabindex="-1"><a class="header-anchor" href="#introduction" aria-hidden="true">#</a> Introduction</h2><p>本文的主要贡献：</p><ul><li>我们提出了一种新颖的可通用人体 GS 网络，用于从单张图像进行高保真人体重建</li><li>我们通过利用来自 SMPL 模型的人体几何先验和来自 2D 生成扩散模型的人体外观先验，将结构和外观信息整合到一个通用的Transformer框架中。几何先验有助于稳定生成高质量的人体几何结构，而外观先验则有助于推测穿衣人体的未见部分。</li><li>我们通过引入语义提示、分层监督和定制的损失函数，提升了重建人体模型的保真度。</li></ul><h2 id="method" tabindex="-1"><a class="header-anchor" href="#method" aria-hidden="true">#</a> Method</h2>',8);function p(m,g){const t=r("ExternalLinkIcon");return i(),s("div",null,[h,a("p",null,[a("a",u,[e("项目地址"),o(t)])]),d])}const f=n(c,[["render",p],["__file","HumanSplat.html.vue"]]);export{f as default};
