import{_ as o,r as a,o as i,c as r,b as e,e as t,d as s}from"./app-2117dd6c.js";const c={},d=e("h2",{id:"learning-implicit-templates-for-point-based-clothed-human-modeling",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#learning-implicit-templates-for-point-based-clothed-human-modeling","aria-hidden":"true"},"#"),t(" Learning Implicit Templates for Point-Based Clothed Human Modeling")],-1),l={href:"https://jsnln.github.io/fite/index.html",target:"_blank",rel:"noopener noreferrer"},h=e("p",null,"ECCV 2022",-1),_=e("h2",{id:"abstract",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#abstract","aria-hidden":"true"},"#"),t(" Abstract")],-1),p=e("p",null,"我们提出的 FITE (First-Implicit-Then-Explicit) 是一个先隐后显的框架，用于为穿着服装的数字人建模。我们的框架首先学习表示粗略服装拓扑结构的隐式表面模板，然后利用模板指导点集的生成，进一步捕捉与姿势相关的服装变形（如褶皱）。我们的管道结合了隐式和显式表示法的优点，即能够处理不同的拓扑结构，并能有效捕捉精细细节。我们还提出了扩散蒙皮技术，以方便模板训练，尤其是宽松服装的模板训练，以及通过基于投影的 pose 编码从 mesh 模板中提取 pose 信息，而无需预定义的 UV 贴图或连通性。",-1),m=e("h2",{id:"introduction",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#introduction","aria-hidden":"true"},"#"),t(" Introduction")],-1);function u(f,b){const n=a("ExternalLinkIcon");return i(),r("div",null,[d,e("p",null,[e("a",l,[t("项目地址"),s(n)])]),h,_,p,m])}const g=o(c,[["render",u],["__file","FITE.html.vue"]]);export{g as default};
