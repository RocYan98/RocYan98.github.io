import{_ as n,r as i,o,c as s,b as e,e as a,d as t,f as c}from"./app-aa7f3de7.js";const d={},h=e("h2",{id:"drivable-3d-gaussian-avatars",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#drivable-3d-gaussian-avatars","aria-hidden":"true"},"#"),a(" Drivable 3D Gaussian Avatars")],-1),l={href:"https://zielon.github.io/d3ga/",target:"_blank",rel:"noopener noreferrer"},f=c('<p>arXiv preprint arXiv:2311.08581</p><figure><img src="http://img.rocyan.cn/blog/2024/05/665043cf9cb25.png" alt="Fig. 1: Overview" tabindex="0" loading="lazy"><figcaption>Fig. 1: Overview</figcaption></figure><h2 id="abstract" tabindex="-1"><a class="header-anchor" href="#abstract" aria-hidden="true">#</a> Abstract</h2><p>我们提出了可驱动 3D 高斯数字人 (D3GA)，这是首个用 3DGS 渲染的人体三维可控模型。目前逼真的数字人在训练过程中需要精确的 3D 注册，在测试过程中需要密集的输入图像，或者两者兼而有之。基于神经辐射场的数字人在远程应用中也往往过于缓慢。本研究利用最近提出的 3DGS 技术，以密集配准的多视角视频作为输入，实时渲染逼真的人体。为了对这些基元进行变形，我们放弃了常用的 LBS 变形方法，而采用了经典的体积变形方法：笼式变形。鉴于它们的尺寸较小，我们用关节角度和关键点来驱动这些变形，这更适合通信应用。在使用相同的训练和测试数据时，我们对九个具有不同体形、衣服和动作的测试者进行了实验，结果比最先进的方法质量更高。</p><h2 id="introduction" tabindex="-1"><a class="header-anchor" href="#introduction" aria-hidden="true">#</a> Introduction</h2><h2 id="reference" tabindex="-1"><a class="header-anchor" href="#reference" aria-hidden="true">#</a> Reference</h2>',6),_={href:"https://arxiv.org/abs/2311.08581",target:"_blank",rel:"noopener noreferrer"};function p(u,b){const r=i("ExternalLinkIcon");return o(),s("div",null,[h,e("p",null,[e("a",l,[a("项目地址"),t(r)])]),f,e("p",null,[e("a",_,[a("[1]Drivable 3D Gaussian Avatars"),t(r)])])])}const v=n(d,[["render",p],["__file","D3GA.html.vue"]]);export{v as default};
