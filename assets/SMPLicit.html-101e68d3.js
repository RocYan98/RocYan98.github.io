const e=JSON.parse(`{"key":"v-3cb22ac6","path":"/posts/paper/SMPLicit.html","title":"SMPLicit-论文笔记","lang":"zh-CN","frontmatter":{"date":"2024-03-24T00:00:00.000Z","category":"论文","tag":["Paper","SMPLicit","Reconstructing","Cloth Simulation"],"title":"SMPLicit-论文笔记","order":8,"description":"SMPLicit: Topology-aware Generative Model for Clothed People 项目地址 CVPR 2021 Abstract 在本文中，我们介绍了 SMPLicit，这是一可以联合表示身体姿势、形状和服装几何形状的模型。现有的基于学习的方法需要为每种类型的服装训练特定的模型，相比之下，SMPLicit 能以统一的方式表示不同的服装拓扑结构 (如无袖上衣、连帽衫和开襟夹克)，同时控制其他属性，如服装尺寸或松紧度。我们展示了我们的模型适用于各种服装，包括 T 恤、连帽衫、夹克、短裤、裤子、裙子、鞋子甚至头发。SMPLicit 的表示灵活性建立在一个以 SMPL 人体参数为条件的隐式模型和一个可学习的潜在空间之上，该潜在空间在语义上可解释并与服装属性相一致。所提出的模型是完全可微分的，因此可用于更大的端到端可训练系统。在实验部分，我们展示了 SMPLicit 可用于三维扫描拟合和着装者图像的三维重建。在这两种情况下，我们在复杂的服装几何图形、处理多层服装的情况以及提供方便的服装编辑工具等方面都超越现有技术水平。","head":[["meta",{"property":"og:url","content":"https://rocyan.top/posts/paper/SMPLicit.html"}],["meta",{"property":"og:site_name","content":"Roc Yan's Blog"}],["meta",{"property":"og:title","content":"SMPLicit-论文笔记"}],["meta",{"property":"og:description","content":"SMPLicit: Topology-aware Generative Model for Clothed People 项目地址 CVPR 2021 Abstract 在本文中，我们介绍了 SMPLicit，这是一可以联合表示身体姿势、形状和服装几何形状的模型。现有的基于学习的方法需要为每种类型的服装训练特定的模型，相比之下，SMPLicit 能以统一的方式表示不同的服装拓扑结构 (如无袖上衣、连帽衫和开襟夹克)，同时控制其他属性，如服装尺寸或松紧度。我们展示了我们的模型适用于各种服装，包括 T 恤、连帽衫、夹克、短裤、裤子、裙子、鞋子甚至头发。SMPLicit 的表示灵活性建立在一个以 SMPL 人体参数为条件的隐式模型和一个可学习的潜在空间之上，该潜在空间在语义上可解释并与服装属性相一致。所提出的模型是完全可微分的，因此可用于更大的端到端可训练系统。在实验部分，我们展示了 SMPLicit 可用于三维扫描拟合和着装者图像的三维重建。在这两种情况下，我们在复杂的服装几何图形、处理多层服装的情况以及提供方便的服装编辑工具等方面都超越现有技术水平。"}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2024-05-07T03:42:30.000Z"}],["meta",{"property":"article:author","content":"Roc Yan"}],["meta",{"property":"article:tag","content":"Paper"}],["meta",{"property":"article:tag","content":"SMPLicit"}],["meta",{"property":"article:tag","content":"Reconstructing"}],["meta",{"property":"article:tag","content":"Cloth Simulation"}],["meta",{"property":"article:published_time","content":"2024-03-24T00:00:00.000Z"}],["meta",{"property":"article:modified_time","content":"2024-05-07T03:42:30.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"SMPLicit-论文笔记\\",\\"image\\":[\\"\\"],\\"datePublished\\":\\"2024-03-24T00:00:00.000Z\\",\\"dateModified\\":\\"2024-05-07T03:42:30.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"Roc Yan\\",\\"url\\":\\"https://rocyan.top\\",\\"email\\":\\"qpyan23@m.fudan.edu.cn\\"}]}"]]},"headers":[{"level":2,"title":"SMPLicit: Topology-aware Generative Model for Clothed People","slug":"smplicit-topology-aware-generative-model-for-clothed-people","link":"#smplicit-topology-aware-generative-model-for-clothed-people","children":[]},{"level":2,"title":"Abstract","slug":"abstract","link":"#abstract","children":[]},{"level":2,"title":"Introduction","slug":"introduction","link":"#introduction","children":[]},{"level":2,"title":"SMPLicit","slug":"smplicit","link":"#smplicit","children":[{"level":3,"title":"SMPLicit-Core Formulation","slug":"smplicit-core-formulation","link":"#smplicit-core-formulation","children":[]},{"level":3,"title":"SMPLicit-core Training","slug":"smplicit-core-training","link":"#smplicit-core-training","children":[]},{"level":3,"title":"SMPLicit-core Inference","slug":"smplicit-core-inference","link":"#smplicit-core-inference","children":[]},{"level":3,"title":"Pose Dependent Deformation","slug":"pose-dependent-deformation","link":"#pose-dependent-deformation","children":[]}]},{"level":2,"title":"Reference","slug":"reference","link":"#reference","children":[]}],"git":{"createdTime":1711422146000,"updatedTime":1715053350000,"contributors":[{"name":"Yan","email":"rocyan98@gmail.com","commits":4}]},"readingTime":{"minutes":5.31,"words":1593},"filePathRelative":"posts/paper/SMPLicit.md","localizedDate":"2024年3月24日","excerpt":"<h2> SMPLicit: Topology-aware Generative Model for Clothed People</h2>\\n<p><a href=\\"http://www.iri.upc.edu/people/ecorona/smplicit/\\" target=\\"_blank\\" rel=\\"noopener noreferrer\\">项目地址</a></p>\\n<p>CVPR 2021</p>\\n<h2> Abstract</h2>\\n<p>在本文中，我们介绍了 SMPLicit，这是一可以联合表示身体姿势、形状和服装几何形状的模型。现有的基于学习的方法需要为每种类型的服装训练特定的模型，相比之下，SMPLicit 能以统一的方式表示不同的服装拓扑结构 (如无袖上衣、连帽衫和开襟夹克)，同时控制其他属性，如服装尺寸或松紧度。我们展示了我们的模型适用于各种服装，包括 T 恤、连帽衫、夹克、短裤、裤子、裙子、鞋子甚至头发。SMPLicit 的表示灵活性建立在一个以 SMPL 人体参数为条件的隐式模型和一个可学习的潜在空间之上，该潜在空间在语义上可解释并与服装属性相一致。所提出的模型是完全可微分的，因此可用于更大的端到端可训练系统。在实验部分，我们展示了 SMPLicit 可用于三维扫描拟合和着装者图像的三维重建。在这两种情况下，我们在复杂的服装几何图形、处理多层服装的情况以及提供方便的服装编辑工具等方面都超越现有技术水平。</p>","autoDesc":true}`);export{e as data};
